{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e937c5",
   "metadata": {},
   "source": [
    "# Evaluate Atac Seq Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df641d71",
   "metadata": {},
   "source": [
    "In this notebook, we're going to train our model using the Mouse Brain dataset (GSE60361). \n",
    "\n",
    "This assumes that you've made the graph using the ```Infer GRN.ipynb``` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a9a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.8.0+cu111\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.0.3\n",
      "Torch version: 1.8.0+cu111\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.0.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from tqdm import tqdm\n",
    "from datasets.datasetAtacSeqChromatin import AtacSeqChromatinDataset\n",
    "from datasets.datasetAtacSeq import AtacSeqDataset\n",
    "from scipy.special import softmax\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (auc, precision_recall_curve, roc_auc_score,\n",
    "                             roc_curve)\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb74981",
   "metadata": {},
   "source": [
    "## Atac Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62851b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103480/103480 [00:04<00:00, 20884.11it/s]\n",
      "100%|██████████| 103480/103480 [00:05<00:00, 20659.65it/s]\n"
     ]
    }
   ],
   "source": [
    "datasetChromatin = AtacSeqChromatinDataset(\"/gpfs/data/rsingh47/hzaki1/atacseqdataChromatin\")\n",
    "datasetReg = AtacSeqDataset(\"/gpfs/data/rsingh47/hzaki1/atacseqdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6602b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name):\n",
    "    with open('/gpfs/data/rsingh47/hzaki1/atacseqdata/obj/' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('/gpfs/data/rsingh47/hzaki1/atacseqdata/obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d22d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDict(dictionary):\n",
    "    return {k: v for k, v in sorted(dictionary.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1342d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretationChromatin = load_obj('interpretationAtacSeq_datasetaugmentation')\n",
    "\n",
    "# interpretationReg = {\n",
    "#     'BJ' : load_obj('interpretationBJ'),\n",
    "#     'GM' : load_obj('interpretationGM'),\n",
    "#     'H1' : load_obj('interpretationH1'),\n",
    "#     'K562' : load_obj('interpretationK562')\n",
    "# }\n",
    "\n",
    "interpretationReg = load_obj('interpretationWoAtacSeq_datasetaugmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3289d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToIndicies(lis,dataset):\n",
    "    toReturn = []\n",
    "    for ele in lis:\n",
    "        toReturn.append(dataset.geneToIndex[ele])\n",
    "    return toReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8e055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ee60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "matChr = np.zeros((1047,18666,2))\n",
    "for count,data in enumerate(datasetChromatin):\n",
    "    matChr[count] = data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4680e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "matReg = np.zeros((1047,18666))\n",
    "for count,data in enumerate(datasetReg):\n",
    "    matReg[count] = data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6444c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((1047))\n",
    "for count,data in enumerate(datasetReg):\n",
    "    labels[count] = data.y.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a2b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "matChrFil = np.zeros((1047,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca7eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cell in enumerate(matChr):\n",
    "    cellType = datasetChromatin.indexToCell[labels[index]]\n",
    "    matChrFil[index] = np.take(cell, convertToIndicies(list(sortDict(interpretationChromatin[cellType]).keys())[0:10], datasetChromatin), axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c28adede",
   "metadata": {},
   "outputs": [],
   "source": [
    "matRegFil = np.zeros((1047,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "128d9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cell in enumerate(matReg):\n",
    "    cellType = datasetReg.indexToCell[labels[index]]\n",
    "    matRegFil[index] = np.take(cell, convertToIndicies(list(sortDict(interpretationReg[cellType]).keys())[0:10], datasetReg),axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a05a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.loadtxt('shuffle_indices/atacseqShuffleIndex.txt')\n",
    "shuffle_index = shuffle_index.astype(np.int32)\n",
    "train_size, val_size = int(len(shuffle_index)* 0.8), int(len(shuffle_index)* 0.9)\n",
    "train_indices = shuffle_index[0:train_size]\n",
    "val_indices = shuffle_index[train_size: val_size]\n",
    "test_indices =  shuffle_index[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c6b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indiciesTrainTest = np.arange(1047)\n",
    "# np.random.shuffle(indiciesTrainTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "560e4a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = indiciesTrainTest[0:835]\n",
    "# test = indiciesTrainTest[835:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50e0f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.take(matRegFil, train_indices, axis=0)\n",
    "testing = np.take(matRegFil, test_indices, axis=0)\n",
    "trainLabels = np.take(labels, train_indices)\n",
    "testLabels = np.take(labels, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27cd73b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(training, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced3b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logisticRegr.score(testing, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a27a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76aea8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.take(matChrFil, train_indices, axis=0)\n",
    "testing = np.take(matChrFil, test_indices, axis=0)\n",
    "trainLabels = np.take(labels, train_indices)\n",
    "testLabels = np.take(labels, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fae39442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(training[:,:,0], trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "434b2f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(testing[:,:,0], testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26b48986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(training[:,:,1], trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb6b8838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9238095238095239"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(testing[:,:,1], testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73726fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.take(matReg, train_indices, axis=0)\n",
    "testing = np.take(matReg, test_indices, axis=0)\n",
    "trainLabels = np.take(labels, train_indices)\n",
    "testLabels = np.take(labels, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "062c2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(training, trainLabels)\n",
    "score = logisticRegr.score(testing, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97ed6b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904761904761905"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score # full expressiono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27555aab",
   "metadata": {},
   "source": [
    "## Mouse Brain Interpretation (to test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c17f0ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.8.0+cu111\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243075/243075 [00:11<00:00, 21095.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets.datasetMouseBrain import MouseBrainDataset\n",
    "datasetMB = MouseBrainDataset(\"/gpfs/data/rsingh47/hzaki1/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14f3dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name):\n",
    "    with open('obj/' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d13c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbInt = load_obj('InterpretationDictNov22_mouseBrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d84bb923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interneurons': 0,\n",
       " 'pyramidal SS': 1,\n",
       " 'pyramidal CA1': 2,\n",
       " 'oligodendrocytes': 3,\n",
       " 'microglia': 4,\n",
       " 'endothelial-mural': 5,\n",
       " 'astrocytes_ependymal': 6}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetMB.cellToIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37d4dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsMB = np.zeros((3005))\n",
    "for count,data in enumerate(datasetMB):\n",
    "    labelsMB[count] = data.y.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f3a6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "matMB = np.zeros((3005,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b791d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "matMBfull = np.zeros((3005,19972))\n",
    "for count,data in enumerate(datasetMB):\n",
    "    matMBfull[count] = data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "585cb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cell in enumerate(matMBfull):\n",
    "    cellType = datasetMB.indexToCell[labelsMB[index]]\n",
    "    matMB[index] = np.take(cell, convertToIndicies(list(sortDict(mbInt[cellType]).keys())[0:20], datasetMB) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3e80420",
   "metadata": {},
   "outputs": [],
   "source": [
    "indiciesTrainTest = np.arange(3005)\n",
    "np.random.shuffle(indiciesTrainTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10877608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = indiciesTrainTest[0:2405]\n",
    "test = indiciesTrainTest[2405:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ce4cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingMB = np.take(matMB, train, axis=0)\n",
    "testingMB = np.take(matMB, test, axis=0)\n",
    "trainLabels = np.take(labelsMB, train)\n",
    "testLabels = np.take(labelsMB, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0e38649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(trainingMB, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cbec3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logisticRegr.score(testingMB, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c73ccb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9183333333333333"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f92c8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/hzaki1/celltypefromgrn/env-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9783333333333334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingFull = np.take(matMBfull, train, axis=0)\n",
    "testingFull = np.take(matMBfull, test, axis=0)\n",
    "trainLabels = np.take(labelsMB, train)\n",
    "testLabels = np.take(labelsMB, test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(trainingFull, trainLabels)\n",
    "\n",
    "logisticRegr.score(testingFull, testLabels)\n",
    "\n",
    "#without key genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c240a",
   "metadata": {},
   "source": [
    "## Baron Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13121626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.8.0+cu111\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181366/181366 [00:08<00:00, 20972.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets.datasetbaronhuman import BaronHumanDataset\n",
    "\n",
    "datasetBH = BaronHumanDataset(\"/gpfs/data/rsingh47/hzaki1/data-baron-human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5af77cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name):\n",
    "    with open('obj/' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fd9fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "datasetBH = datasetBH.shuffle()\n",
    "\n",
    "matBHFull = np.zeros((8569,17499))\n",
    "labelsBH = np.zeros((8569))\n",
    "for count, data in enumerate(datasetBH):\n",
    "    matBHFull[count] = data.x\n",
    "    labelsBH[count] = data.y.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e1b08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indiciesTrainTestBH = np.arange(8569)\n",
    "np.random.shuffle(indiciesTrainTestBH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da1345eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBH = indiciesTrainTestBH[0:6855]\n",
    "testBH = indiciesTrainTestBH[6855:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37cca80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/hzaki1/celltypefromgrn/env-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09918319719953325"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainingBH = np.take(matBHFull, trainBH, axis=0)\n",
    "# testingBH = np.take(matBHFull, testBH, axis=0)\n",
    "trainingBH = matBHFull[0:6855]\n",
    "testingBH = matBHFull[6855:]\n",
    "trainLabelsBH = labelsBH[0:6855]\n",
    "testLabelsBH = labelsBH[6855:]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(trainingBH, trainLabelsBH)\n",
    "\n",
    "logisticRegr.score(testingBH, testLabelsBH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45cd90cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8569, 17499)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matBHFull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbcf12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhInt = load_obj('InterpretationDictNov20_baronhuman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2165e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "matBH = np.zeros((8569,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6e9913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cell in enumerate(matBHFull):\n",
    "    cellType = datasetBH.indexToCell[labelsBH[index]]\n",
    "    matBH[index] = np.take(cell, convertToIndicies(list(sortDict(bhInt[cellType]).keys())[0:10], datasetBH) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27456285",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingBHFil = matBH[0:6855]\n",
    "testingBHFil = matBH[6855:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7b11311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/hzaki1/celltypefromgrn/env-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09918319719953325"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(trainingBHFil, trainLabelsBH)\n",
    "\n",
    "logisticRegr.score(testingBHFil, testLabelsBH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31af51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
